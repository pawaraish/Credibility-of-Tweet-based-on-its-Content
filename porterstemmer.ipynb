{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S34EEMlgnP3Y",
        "outputId": "33a400b5-2269-449a-b69b-58fc5e90cea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello INTJ\n",
            ", PUNCT\n",
            "I PRON\n",
            "am AUX\n",
            "non ADJ\n",
            "- ADJ\n",
            "vegetarian ADJ\n",
            ", PUNCT\n",
            "email VERB\n",
            "me PRON\n",
            "the DET\n",
            "menu NOUN\n",
            "at ADP\n",
            "abc PROPN\n",
            "- PROPN\n",
            "xyz@gmai.comHello PROPN\n",
            ", PUNCT\n",
            "I PRON\n",
            "am AUX\n",
            "non ADJ\n",
            "- ADJ\n",
            "vegetarian ADJ\n",
            ", PUNCT\n",
            "email VERB\n",
            "me PRON\n",
            "the DET\n",
            "menu NOUN\n",
            "at ADP\n",
            "abc-xyz@gmai.com PROPN\n",
            "abc-xyz@gmai.comHello - ORG - Companies, agencies, institutions, etc.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "sentence = sp(u'Hello, I am non-vegetarian, email me the menu at abc-xyz@gmai.comHello, I am non-vegetarian, email me the menu at abc-xyz@gmai.com')\n",
        "for word in sentence:\n",
        "  print(word.text, word.pos_)\n",
        "for entity in sentence.ents:\n",
        "  print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtvqHbmWuKvj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q94J6s-ztiaD",
        "outputId": "868d58ce-68ad-49f2-bb80-b98d2fe295a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " --> \n",
            "eaten --> eaten\n",
            "played --> play\n",
            "playing --> play\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "tokens = ['', 'eaten', 'played', 'playing']\n",
        "for token in tokens:\n",
        "    print(token + ' --> ' + stemmer.stem(token))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rEKVWtbwzlM",
        "outputId": "ae77edaa-e824-4a8c-960b-3f150258fc23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "compute --> comput\n",
            "computer --> comput\n",
            "computed --> comput\n",
            "computing --> comput\n",
            "compute compute\n",
            "computer computer\n",
            "computed compute\n",
            "computing computing\n",
            "accident  ===> accident\n",
            "had  ===> have\n",
            "took  ===> take\n",
            "placed  ===> place\n",
            "at  ===> at\n",
            "margao  ===> margao\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "tokens = ['compute', 'computer', 'computed', 'computing']\n",
        "\n",
        "for token in tokens:\n",
        "    print(token + ' --> ' + stemmer.stem(token))\n",
        "sentence6 = sp(u'compute computer computed computing')\n",
        "for word in sentence6:\n",
        "    print(word.text,  word.lemma_)\n",
        "sentence7 = sp(u'accident had took placed at margao')\n",
        "\n",
        "for word in sentence7:\n",
        "    print(word.text + '  ===>', word.lemma_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKUjF1khrOI8",
        "outputId": "616556ba-1d96-4841-b69b-2f536a9a8009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I PRON\n",
            "have AUX\n",
            "eaten VERB\n",
            "vegetarian NOUN\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import nltk\n",
        "\n",
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "sentence = sp(u'I have eaten vegetarian')\n",
        "for word in sentence:\n",
        "  print(word.text, word.pos_)\n",
        "for entity in sentence.ents:\n",
        "  print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))\n",
        "  tokens = ['vegetarian', 'eaten']\n",
        "  for token in tokens:\n",
        "    print(token + ' --> ' + stemmer.stem(token))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
